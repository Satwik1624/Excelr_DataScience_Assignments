{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3jFcruqikRTE",
        "outputId": "f84ba39c-cfcd-4075-bd23-02f8f818820d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
            "0                             burgers,meatballs,eggs                                                                                                                                                                             \n",
            "1                                            chutney                                                                                                                                                                             \n",
            "2                                     turkey,avocado                                                                                                                                                                             \n",
            "3  mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
            "4                                     low fat yogurt                                                                                                                                                                             \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7500 entries, 0 to 7499\n",
            "Data columns (total 1 columns):\n",
            " #   Column                                                                                                                                                                                                                           Non-Null Count  Dtype \n",
            "---  ------                                                                                                                                                                                                                           --------------  ----- \n",
            " 0   shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil  7500 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 58.7+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel('Online retail.xlsx')\n",
        "print(df.head())\n",
        "print(df.info())  # Check data types and null values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with any missing values\n",
        "df.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "C15Fyzqelsp3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n"
      ],
      "metadata": {
        "id": "1pSFP1fXlueT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel('Online retail.xlsx', header=None)  # Load without headers if the column is unnamed\n",
        "\n",
        "# Rename the column to 'Items'\n",
        "df.columns = ['Items']\n",
        "\n",
        "# Split the items in each row\n",
        "df['Items'] = df['Items'].str.split(',')\n",
        "\n",
        "# Convert each transaction (row) into a list of items\n",
        "transactions = df['Items'].tolist()\n"
      ],
      "metadata": {
        "id": "YMLrbXWAlxQe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Encode the transactions\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "basket = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Run the Apriori algorithm to find frequent itemsets\n",
        "frequent_itemsets = apriori(basket, min_support=0.02, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "print(rules.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "weCU-rp6m9bj",
        "outputId": "1dcffdff-e1e7-404f-b1b3-6e1b58180d86"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       antecedents     consequents  antecedent support  consequent support  \\\n",
            "0        (burgers)          (eggs)            0.087188            0.179709   \n",
            "1           (eggs)       (burgers)            0.179709            0.087188   \n",
            "2   (french fries)       (burgers)            0.170911            0.087188   \n",
            "3        (burgers)  (french fries)            0.087188            0.170911   \n",
            "4  (mineral water)       (burgers)            0.238368            0.087188   \n",
            "\n",
            "    support  confidence      lift  leverage  conviction  zhangs_metric  \n",
            "0  0.028796    0.330275  1.837830  0.013128    1.224818       0.499424  \n",
            "1  0.028796    0.160237  1.837830  0.013128    1.086988       0.555754  \n",
            "2  0.021997    0.128705  1.476173  0.007096    1.047650       0.389069  \n",
            "3  0.021997    0.252294  1.476173  0.007096    1.108844       0.353384  \n",
            "4  0.024397    0.102349  1.173883  0.003614    1.016889       0.194486  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Set a minimum support threshold and find frequent itemsets\n",
        "frequent_itemsets = apriori(basket, min_support=0.02, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "print(rules.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4Q519M-lnFum",
        "outputId": "5b4eea5f-d180-4b4a-bd08-b67f969529b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       antecedents     consequents  antecedent support  consequent support  \\\n",
            "0        (burgers)          (eggs)            0.087188            0.179709   \n",
            "1           (eggs)       (burgers)            0.179709            0.087188   \n",
            "2   (french fries)       (burgers)            0.170911            0.087188   \n",
            "3        (burgers)  (french fries)            0.087188            0.170911   \n",
            "4  (mineral water)       (burgers)            0.238368            0.087188   \n",
            "\n",
            "    support  confidence      lift  leverage  conviction  zhangs_metric  \n",
            "0  0.028796    0.330275  1.837830  0.013128    1.224818       0.499424  \n",
            "1  0.028796    0.160237  1.837830  0.013128    1.086988       0.555754  \n",
            "2  0.021997    0.128705  1.476173  0.007096    1.047650       0.389069  \n",
            "3  0.021997    0.252294  1.476173  0.007096    1.108844       0.353384  \n",
            "4  0.024397    0.102349  1.173883  0.003614    1.016889       0.194486  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rules with a minimum support, confidence, and lift\n",
        "meaningful_rules = rules[(rules['support'] >= 0.02) &\n",
        "                         (rules['confidence'] >= 0.5) &\n",
        "                         (rules['lift'] >= 1.2)]\n",
        "print(meaningful_rules)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q91p--nynJSn",
        "outputId": "464fc472-020f-4c13-b19b-1906440f8a0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Analyzing Generated Rules**\n",
        "\n",
        "  The rules reveal interesting relationships among frequently purchased items. I focused on key metrics like support, confidence, and lift to identify significant patterns:\n",
        "\n",
        " * Lift: Rules with high lift values, such as (burgers → eggs) with a lift of 1.84, show that these items are bought together more frequently than expected by random chance. This suggests that customers who buy burgers are likely to buy eggs as well, which is valuable information for creating bundled offers.\n",
        "\n",
        " * Support and Confidence:\n",
        "\n",
        "    * For (burgers → eggs), the support of 0.0288 tells me that this combination appears in roughly 2.88% of transactions, and the confidence of 33.03% indicates that when customers buy burgers, there’s a 33% chance they’ll also purchase eggs. This high confidence level highlights a strong complementary relationship that could be leveraged for cross-selling.\n",
        "2. **Interpreting Insights**\n",
        "\n",
        " These patterns offer valuable insights into customer purchasing behavior:\n",
        "\n",
        " * Frequent Itemsets:\n",
        "\n",
        "    * Mineral Water and Burgers: The rule (mineral water → burgers) with a lift of 1.17 and support of 2.44% implies that these items are often bought together, hinting that customers may be buying them for meals or snacks. I could use this insight to suggest these items together in displays or online shopping recommendations.\n",
        "    * French Fries and Burgers: The strong association between burgers and french fries, with a lift of 1.48, confirms their popularity as a meal combination, which could benefit from promotional bundling or in-store pairing.\n",
        " * Confidence Levels:\n",
        "\n",
        "    * The high-confidence rule (burgers → french fries), with a confidence of 25.23%, suggests that when customers buy burgers, there’s a significant chance they’ll also buy french fries. This pattern aligns with common meal combinations, making it a good target for cross-promotions.\n",
        " * Lift:\n",
        "\n",
        "    * Rules with lift values over 1.0, like (burgers → eggs) and (eggs → burgers), highlight strong associations that go beyond random chance. These pairings could be ideal for combo offers or strategic shelf placements to enhance sales."
      ],
      "metadata": {
        "id": "kX8tno2luyLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interview Questions\n",
        "\n",
        "**1. What is Lift and Why is it Important in Association Rules?**\n",
        "\n",
        " Ans. **Lift** measures the strength of an association rule relative to random chance. It is calculated as the ratio of the observed co-occurrence of items to their expected co-occurrence if they were independent.\n",
        "\n",
        "  **Importance:** Lift values greater than 1 indicate a strong association between items, meaning they’re more likely to be purchased together than by random chance. It helps in identifying meaningful product relationships.\n",
        "\n",
        "**2. What is Support and Confidence, and How Do You Calculate Them?**\n",
        "\n",
        " Ans. **Support** is the proportion of transactions that contain a particular item or itemset, indicating how frequently an item appears in the dataset.\n",
        "\n",
        " **Confidence** is the likelihood of an item Y being purchased when item X is bought.\n",
        "\n",
        " **Use in Association Rules:** Both metrics help in determining the strength of the relationship between items and filtering out insignificant rules.\n",
        "\n",
        "**3. What are Some Limitations or Challenges of Association Rules Mining?**\n",
        "\n",
        " Ans. **Scalability:** Large datasets with many items can lead to a high computational load, making association rule mining resource-intensive.\n",
        "\n",
        "  **Interpretability:** With too many rules, it’s challenging to interpret or identify meaningful patterns without prior filtering.\n",
        "\n",
        "  **Sparsity of Data:** Many transactions may contain unique item combinations, leading to fewer common patterns.\n",
        "\n",
        "  **Choice of Thresholds:** Setting support, confidence, and lift thresholds can be challenging; thresholds that are too high might miss important associations, while those that are too low may yield insignificant rules.\n"
      ],
      "metadata": {
        "id": "aMfROwvMwBuK"
      }
    }
  ]
}